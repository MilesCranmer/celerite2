// NOTE: This file was autogenerated
// NOTE: Changes should be made to the template

// Generated JAX FFI bindings for celerite2.
// Regenerate with: python python/spec/generate.py

#include <pybind11/pybind11.h>
#include <Eigen/Core>
#include <string>

#include "xla/ffi/api/ffi.h"
#include "xla/ffi/api/api.h"

#include "../driver.hpp"

namespace py = pybind11;
namespace ffi = xla::ffi;
using namespace celerite2::driver;

// Helpers
template <typename Buffer>
inline Eigen::Index dim0(const Buffer& buf) {
  return static_cast<Eigen::Index>(buf.dimensions()[0]);
}
template <typename Buffer>
inline Eigen::Index dim1(const Buffer& buf) {
  return static_cast<Eigen::Index>(buf.dimensions()[1]);
}
template <typename Buffer>
inline Eigen::Index flat_cols(const Buffer& buf) {
  const auto& dims = buf.dimensions();
  Eigen::Index cols = 1;
  for (size_t i = 1; i < dims.size(); ++i)
    cols *= static_cast<Eigen::Index>(dims[i]);
  return cols;
}

inline ffi::Error shape_error(const char* msg) {
  return ffi::Error(ffi::ErrorCode::kInvalidArgument, std::string(msg));
}

// === AUTO-GENERATED KERNELS ===


ffi::Error FactorImpl(
    ffi::Buffer<ffi::DataType::F64> t,
    ffi::Buffer<ffi::DataType::F64> c,
    ffi::Buffer<ffi::DataType::F64> a,
    ffi::Buffer<ffi::DataType::F64> U,
    ffi::Buffer<ffi::DataType::F64> V,
    ffi::ResultBuffer<ffi::DataType::F64> d,
    ffi::ResultBuffer<ffi::DataType::F64> W,
    ffi::ResultBuffer<ffi::DataType::F64> S
) {


  if (dim0(t) != N) return shape_error("factor shape mismatch");

  if (dim0(c) != J) return shape_error("factor shape mismatch");

  if (dim0(a) != N) return shape_error("factor shape mismatch");

  if (dim0(U) != N || dim1(U) != J) return shape_error("factor shape mismatch");

  if (dim0(V) != N || dim1(V) != J) return shape_error("factor shape mismatch");


#define FIXED_SIZE_MAP(SIZE)                                                        \
  {                                                                                 \
    Eigen::Map<const Eigen::VectorXd> t_(t.typed_data(), N, 1); \
    Eigen::Map<const Eigen::VectorXd> c_(c.typed_data(), J, 1); \
    Eigen::Map<const Eigen::VectorXd> a_(a.typed_data(), N, 1); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> U_(U.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> V_(V.typed_data(), N, J); \
    Eigen::Map<Eigen::VectorXd> d_(d->typed_data(), N, 1); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> W_(W->typed_data(), N, J); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, (SIZE * SIZE), order<(SIZE * SIZE)>::value>> S_(S->typed_data(), N, J * J); \
    d_.setZero(); \
    W_.setZero(); \
    S_.setZero(); \
    celerite2::core::factor( t_, c_, a_, U_, V_, d_,W_,S_); \
  }
  UNWRAP_CASES_FEW
#undef FIXED_SIZE_MAP

  return ffi::Error::Success();
}

XLA_FFI_DEFINE_HANDLER_SYMBOL(
    factor, FactorImpl,
    ffi::Ffi::Bind()
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // t
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // c
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // a
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // U
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // V
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // d
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // W
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // S
);


ffi::Error factor_revImpl(
    ffi::Buffer<ffi::DataType::F64> t,
    ffi::Buffer<ffi::DataType::F64> c,
    ffi::Buffer<ffi::DataType::F64> a,
    ffi::Buffer<ffi::DataType::F64> U,
    ffi::Buffer<ffi::DataType::F64> V,
    ffi::Buffer<ffi::DataType::F64> d,
    ffi::Buffer<ffi::DataType::F64> W,
    ffi::Buffer<ffi::DataType::F64> S,
    ffi::Buffer<ffi::DataType::F64> bd,
    ffi::Buffer<ffi::DataType::F64> bW,
    ffi::ResultBuffer<ffi::DataType::F64> bt,
    ffi::ResultBuffer<ffi::DataType::F64> bc,
    ffi::ResultBuffer<ffi::DataType::F64> ba,
    ffi::ResultBuffer<ffi::DataType::F64> bU,
    ffi::ResultBuffer<ffi::DataType::F64> bV
) {


  if (dim0(t) != N) return shape_error("factor_rev shape mismatch");

  if (dim0(c) != J) return shape_error("factor_rev shape mismatch");

  if (dim0(a) != N) return shape_error("factor_rev shape mismatch");

  if (dim0(U) != N || dim1(U) != J) return shape_error("factor_rev shape mismatch");

  if (dim0(V) != N || dim1(V) != J) return shape_error("factor_rev shape mismatch");

  if (dim0(d) != N) return shape_error("factor_rev shape mismatch");

  if (dim0(W) != N || dim1(W) != J) return shape_error("factor_rev shape mismatch");


  if (dim0(bd) != N) return shape_error("factor_rev shape mismatch");

  if (dim0(bW) != N || dim1(bW) != J) return shape_error("factor_rev shape mismatch");


#define FIXED_SIZE_MAP(SIZE)                                                        \
  {                                                                                 \
    Eigen::Map<const Eigen::VectorXd> t_(t.typed_data(), N, 1); \
    Eigen::Map<const Eigen::VectorXd> c_(c.typed_data(), J, 1); \
    Eigen::Map<const Eigen::VectorXd> a_(a.typed_data(), N, 1); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> U_(U.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> V_(V.typed_data(), N, J); \
    Eigen::Map<const Eigen::VectorXd> d_(d.typed_data(), N, 1); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> W_(W.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> S_(S.typed_data(), N, dim1(S)); \
    Eigen::Map<const Eigen::VectorXd> bd_(bd.typed_data(), N, 1); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> bW_(bW.typed_data(), N, J); \
    Eigen::Map<Eigen::VectorXd> bt_(bt->typed_data(), N, 1); \
    Eigen::Map<Eigen::VectorXd> bc_(bc->typed_data(), J, 1); \
    Eigen::Map<Eigen::VectorXd> ba_(ba->typed_data(), N, 1); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> bU_(bU->typed_data(), N, J); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> bV_(bV->typed_data(), N, J); \
    bt_.setZero(); \
    bc_.setZero(); \
    ba_.setZero(); \
    bU_.setZero(); \
    bV_.setZero(); \
    celerite2::core::factor_rev( t_, c_, a_, U_, V_, d_, W_, S_, bd_, bW_, bt_,bc_,ba_,bU_,bV_); \
  }
  UNWRAP_CASES_FEW
#undef FIXED_SIZE_MAP

  return ffi::Error::Success();
}

XLA_FFI_DEFINE_HANDLER_SYMBOL(
    factor_rev, factor_revImpl,
    ffi::Ffi::Bind()
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // t
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // c
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // a
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // U
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // V
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // d
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // W
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // S
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // bd
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // bW
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bt
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bc
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // ba
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bU
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bV
);



ffi::Error Solve_lowerImpl(
    ffi::Buffer<ffi::DataType::F64> t,
    ffi::Buffer<ffi::DataType::F64> c,
    ffi::Buffer<ffi::DataType::F64> U,
    ffi::Buffer<ffi::DataType::F64> W,
    ffi::Buffer<ffi::DataType::F64> Y,
    ffi::ResultBuffer<ffi::DataType::F64> Z,
    ffi::ResultBuffer<ffi::DataType::F64> F
) {


  if (dim0(t) != N) return shape_error("solve_lower shape mismatch");

  if (dim0(c) != J) return shape_error("solve_lower shape mismatch");

  if (dim0(U) != N || dim1(U) != J) return shape_error("solve_lower shape mismatch");

  if (dim0(W) != N || dim1(W) != J) return shape_error("solve_lower shape mismatch");

  if (dim0(Y) != N || dim1(Y) != nrhs) return shape_error("solve_lower shape mismatch");


#define FIXED_SIZE_MAP(SIZE)                                                        \
  {                                                                                 \
    Eigen::Map<const Eigen::VectorXd> t_(t.typed_data(), N, 1); \
    Eigen::Map<const Eigen::VectorXd> c_(c.typed_data(), J, 1); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> U_(U.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> W_(W.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Y_(Y.typed_data(), N, dim1(Y)); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Z_(Z->typed_data(), N, dim1(Z)); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> F_(F->typed_data(), N, flat_cols(F)); \
    Z_.setZero(); \
    F_.setZero(); \
    celerite2::core::solve_lower( t_, c_, U_, W_, Y_, Z_,F_); \
  }
  UNWRAP_CASES_FEW
#undef FIXED_SIZE_MAP

  return ffi::Error::Success();
}

XLA_FFI_DEFINE_HANDLER_SYMBOL(
    solve_lower, Solve_lowerImpl,
    ffi::Ffi::Bind()
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // t
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // c
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // U
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // W
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // Y
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // Z
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // F
);


ffi::Error solve_lower_revImpl(
    ffi::Buffer<ffi::DataType::F64> t,
    ffi::Buffer<ffi::DataType::F64> c,
    ffi::Buffer<ffi::DataType::F64> U,
    ffi::Buffer<ffi::DataType::F64> W,
    ffi::Buffer<ffi::DataType::F64> Y,
    ffi::Buffer<ffi::DataType::F64> Z,
    ffi::Buffer<ffi::DataType::F64> F,
    ffi::Buffer<ffi::DataType::F64> bZ,
    ffi::ResultBuffer<ffi::DataType::F64> bt,
    ffi::ResultBuffer<ffi::DataType::F64> bc,
    ffi::ResultBuffer<ffi::DataType::F64> bU,
    ffi::ResultBuffer<ffi::DataType::F64> bW,
    ffi::ResultBuffer<ffi::DataType::F64> bY
) {


  if (dim0(t) != N) return shape_error("solve_lower_rev shape mismatch");

  if (dim0(c) != J) return shape_error("solve_lower_rev shape mismatch");

  if (dim0(U) != N || dim1(U) != J) return shape_error("solve_lower_rev shape mismatch");

  if (dim0(W) != N || dim1(W) != J) return shape_error("solve_lower_rev shape mismatch");

  if (dim0(Y) != N || dim1(Y) != nrhs) return shape_error("solve_lower_rev shape mismatch");

  if (dim0(Z) != N || dim1(Z) != nrhs) return shape_error("solve_lower_rev shape mismatch");


  if (dim0(bZ) != N || dim1(bZ) != nrhs) return shape_error("solve_lower_rev shape mismatch");


#define FIXED_SIZE_MAP(SIZE)                                                        \
  {                                                                                 \
    Eigen::Map<const Eigen::VectorXd> t_(t.typed_data(), N, 1); \
    Eigen::Map<const Eigen::VectorXd> c_(c.typed_data(), J, 1); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> U_(U.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> W_(W.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Y_(Y.typed_data(), N, dim1(Y)); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Z_(Z.typed_data(), N, dim1(Z)); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> F_(F.typed_data(), N, dim1(F)); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> bZ_(bZ.typed_data(), N, dim1(bZ)); \
    Eigen::Map<Eigen::VectorXd> bt_(bt->typed_data(), N, 1); \
    Eigen::Map<Eigen::VectorXd> bc_(bc->typed_data(), J, 1); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> bU_(bU->typed_data(), N, J); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> bW_(bW->typed_data(), N, J); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> bY_(bY->typed_data(), N, dim1(bY)); \
    bt_.setZero(); \
    bc_.setZero(); \
    bU_.setZero(); \
    bW_.setZero(); \
    bY_.setZero(); \
    celerite2::core::solve_lower_rev( t_, c_, U_, W_, Y_, Z_, F_, bZ_, bt_,bc_,bU_,bW_,bY_); \
  }
  UNWRAP_CASES_FEW
#undef FIXED_SIZE_MAP

  return ffi::Error::Success();
}

XLA_FFI_DEFINE_HANDLER_SYMBOL(
    solve_lower_rev, solve_lower_revImpl,
    ffi::Ffi::Bind()
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // t
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // c
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // U
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // W
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // Y
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // Z
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // F
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // bZ
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bt
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bc
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bU
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bW
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bY
);



ffi::Error Solve_upperImpl(
    ffi::Buffer<ffi::DataType::F64> t,
    ffi::Buffer<ffi::DataType::F64> c,
    ffi::Buffer<ffi::DataType::F64> U,
    ffi::Buffer<ffi::DataType::F64> W,
    ffi::Buffer<ffi::DataType::F64> Y,
    ffi::ResultBuffer<ffi::DataType::F64> Z,
    ffi::ResultBuffer<ffi::DataType::F64> F
) {


  if (dim0(t) != N) return shape_error("solve_upper shape mismatch");

  if (dim0(c) != J) return shape_error("solve_upper shape mismatch");

  if (dim0(U) != N || dim1(U) != J) return shape_error("solve_upper shape mismatch");

  if (dim0(W) != N || dim1(W) != J) return shape_error("solve_upper shape mismatch");

  if (dim0(Y) != N || dim1(Y) != nrhs) return shape_error("solve_upper shape mismatch");


#define FIXED_SIZE_MAP(SIZE)                                                        \
  {                                                                                 \
    Eigen::Map<const Eigen::VectorXd> t_(t.typed_data(), N, 1); \
    Eigen::Map<const Eigen::VectorXd> c_(c.typed_data(), J, 1); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> U_(U.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> W_(W.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Y_(Y.typed_data(), N, dim1(Y)); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Z_(Z->typed_data(), N, dim1(Z)); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> F_(F->typed_data(), N, flat_cols(F)); \
    Z_.setZero(); \
    F_.setZero(); \
    celerite2::core::solve_upper( t_, c_, U_, W_, Y_, Z_,F_); \
  }
  UNWRAP_CASES_FEW
#undef FIXED_SIZE_MAP

  return ffi::Error::Success();
}

XLA_FFI_DEFINE_HANDLER_SYMBOL(
    solve_upper, Solve_upperImpl,
    ffi::Ffi::Bind()
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // t
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // c
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // U
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // W
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // Y
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // Z
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // F
);


ffi::Error solve_upper_revImpl(
    ffi::Buffer<ffi::DataType::F64> t,
    ffi::Buffer<ffi::DataType::F64> c,
    ffi::Buffer<ffi::DataType::F64> U,
    ffi::Buffer<ffi::DataType::F64> W,
    ffi::Buffer<ffi::DataType::F64> Y,
    ffi::Buffer<ffi::DataType::F64> Z,
    ffi::Buffer<ffi::DataType::F64> F,
    ffi::Buffer<ffi::DataType::F64> bZ,
    ffi::ResultBuffer<ffi::DataType::F64> bt,
    ffi::ResultBuffer<ffi::DataType::F64> bc,
    ffi::ResultBuffer<ffi::DataType::F64> bU,
    ffi::ResultBuffer<ffi::DataType::F64> bW,
    ffi::ResultBuffer<ffi::DataType::F64> bY
) {


  if (dim0(t) != N) return shape_error("solve_upper_rev shape mismatch");

  if (dim0(c) != J) return shape_error("solve_upper_rev shape mismatch");

  if (dim0(U) != N || dim1(U) != J) return shape_error("solve_upper_rev shape mismatch");

  if (dim0(W) != N || dim1(W) != J) return shape_error("solve_upper_rev shape mismatch");

  if (dim0(Y) != N || dim1(Y) != nrhs) return shape_error("solve_upper_rev shape mismatch");

  if (dim0(Z) != N || dim1(Z) != nrhs) return shape_error("solve_upper_rev shape mismatch");


  if (dim0(bZ) != N || dim1(bZ) != nrhs) return shape_error("solve_upper_rev shape mismatch");


#define FIXED_SIZE_MAP(SIZE)                                                        \
  {                                                                                 \
    Eigen::Map<const Eigen::VectorXd> t_(t.typed_data(), N, 1); \
    Eigen::Map<const Eigen::VectorXd> c_(c.typed_data(), J, 1); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> U_(U.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> W_(W.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Y_(Y.typed_data(), N, dim1(Y)); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Z_(Z.typed_data(), N, dim1(Z)); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> F_(F.typed_data(), N, dim1(F)); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> bZ_(bZ.typed_data(), N, dim1(bZ)); \
    Eigen::Map<Eigen::VectorXd> bt_(bt->typed_data(), N, 1); \
    Eigen::Map<Eigen::VectorXd> bc_(bc->typed_data(), J, 1); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> bU_(bU->typed_data(), N, J); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> bW_(bW->typed_data(), N, J); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> bY_(bY->typed_data(), N, dim1(bY)); \
    bt_.setZero(); \
    bc_.setZero(); \
    bU_.setZero(); \
    bW_.setZero(); \
    bY_.setZero(); \
    celerite2::core::solve_upper_rev( t_, c_, U_, W_, Y_, Z_, F_, bZ_, bt_,bc_,bU_,bW_,bY_); \
  }
  UNWRAP_CASES_FEW
#undef FIXED_SIZE_MAP

  return ffi::Error::Success();
}

XLA_FFI_DEFINE_HANDLER_SYMBOL(
    solve_upper_rev, solve_upper_revImpl,
    ffi::Ffi::Bind()
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // t
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // c
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // U
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // W
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // Y
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // Z
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // F
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // bZ
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bt
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bc
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bU
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bW
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bY
);



ffi::Error Matmul_lowerImpl(
    ffi::Buffer<ffi::DataType::F64> t,
    ffi::Buffer<ffi::DataType::F64> c,
    ffi::Buffer<ffi::DataType::F64> U,
    ffi::Buffer<ffi::DataType::F64> V,
    ffi::Buffer<ffi::DataType::F64> Y,
    ffi::ResultBuffer<ffi::DataType::F64> Z,
    ffi::ResultBuffer<ffi::DataType::F64> F
) {


  if (dim0(t) != N) return shape_error("matmul_lower shape mismatch");

  if (dim0(c) != J) return shape_error("matmul_lower shape mismatch");

  if (dim0(U) != N || dim1(U) != J) return shape_error("matmul_lower shape mismatch");

  if (dim0(V) != N || dim1(V) != J) return shape_error("matmul_lower shape mismatch");

  if (dim0(Y) != N || dim1(Y) != nrhs) return shape_error("matmul_lower shape mismatch");


#define FIXED_SIZE_MAP(SIZE)                                                        \
  {                                                                                 \
    Eigen::Map<const Eigen::VectorXd> t_(t.typed_data(), N, 1); \
    Eigen::Map<const Eigen::VectorXd> c_(c.typed_data(), J, 1); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> U_(U.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> V_(V.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Y_(Y.typed_data(), N, dim1(Y)); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Z_(Z->typed_data(), N, dim1(Z)); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> F_(F->typed_data(), N, flat_cols(F)); \
    Z_.setZero(); \
    F_.setZero(); \
    celerite2::core::matmul_lower( t_, c_, U_, V_, Y_, Z_,F_); \
  }
  UNWRAP_CASES_FEW
#undef FIXED_SIZE_MAP

  return ffi::Error::Success();
}

XLA_FFI_DEFINE_HANDLER_SYMBOL(
    matmul_lower, Matmul_lowerImpl,
    ffi::Ffi::Bind()
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // t
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // c
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // U
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // V
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // Y
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // Z
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // F
);


ffi::Error matmul_lower_revImpl(
    ffi::Buffer<ffi::DataType::F64> t,
    ffi::Buffer<ffi::DataType::F64> c,
    ffi::Buffer<ffi::DataType::F64> U,
    ffi::Buffer<ffi::DataType::F64> V,
    ffi::Buffer<ffi::DataType::F64> Y,
    ffi::Buffer<ffi::DataType::F64> Z,
    ffi::Buffer<ffi::DataType::F64> F,
    ffi::Buffer<ffi::DataType::F64> bZ,
    ffi::ResultBuffer<ffi::DataType::F64> bt,
    ffi::ResultBuffer<ffi::DataType::F64> bc,
    ffi::ResultBuffer<ffi::DataType::F64> bU,
    ffi::ResultBuffer<ffi::DataType::F64> bV,
    ffi::ResultBuffer<ffi::DataType::F64> bY
) {


  if (dim0(t) != N) return shape_error("matmul_lower_rev shape mismatch");

  if (dim0(c) != J) return shape_error("matmul_lower_rev shape mismatch");

  if (dim0(U) != N || dim1(U) != J) return shape_error("matmul_lower_rev shape mismatch");

  if (dim0(V) != N || dim1(V) != J) return shape_error("matmul_lower_rev shape mismatch");

  if (dim0(Y) != N || dim1(Y) != nrhs) return shape_error("matmul_lower_rev shape mismatch");

  if (dim0(Z) != N || dim1(Z) != nrhs) return shape_error("matmul_lower_rev shape mismatch");


  if (dim0(bZ) != N || dim1(bZ) != nrhs) return shape_error("matmul_lower_rev shape mismatch");


#define FIXED_SIZE_MAP(SIZE)                                                        \
  {                                                                                 \
    Eigen::Map<const Eigen::VectorXd> t_(t.typed_data(), N, 1); \
    Eigen::Map<const Eigen::VectorXd> c_(c.typed_data(), J, 1); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> U_(U.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> V_(V.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Y_(Y.typed_data(), N, dim1(Y)); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Z_(Z.typed_data(), N, dim1(Z)); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> F_(F.typed_data(), N, dim1(F)); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> bZ_(bZ.typed_data(), N, dim1(bZ)); \
    Eigen::Map<Eigen::VectorXd> bt_(bt->typed_data(), N, 1); \
    Eigen::Map<Eigen::VectorXd> bc_(bc->typed_data(), J, 1); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> bU_(bU->typed_data(), N, J); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> bV_(bV->typed_data(), N, J); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> bY_(bY->typed_data(), N, dim1(bY)); \
    bt_.setZero(); \
    bc_.setZero(); \
    bU_.setZero(); \
    bV_.setZero(); \
    bY_.setZero(); \
    celerite2::core::matmul_lower_rev( t_, c_, U_, V_, Y_, Z_, F_, bZ_, bt_,bc_,bU_,bV_,bY_); \
  }
  UNWRAP_CASES_FEW
#undef FIXED_SIZE_MAP

  return ffi::Error::Success();
}

XLA_FFI_DEFINE_HANDLER_SYMBOL(
    matmul_lower_rev, matmul_lower_revImpl,
    ffi::Ffi::Bind()
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // t
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // c
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // U
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // V
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // Y
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // Z
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // F
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // bZ
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bt
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bc
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bU
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bV
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bY
);



ffi::Error Matmul_upperImpl(
    ffi::Buffer<ffi::DataType::F64> t,
    ffi::Buffer<ffi::DataType::F64> c,
    ffi::Buffer<ffi::DataType::F64> U,
    ffi::Buffer<ffi::DataType::F64> V,
    ffi::Buffer<ffi::DataType::F64> Y,
    ffi::ResultBuffer<ffi::DataType::F64> Z,
    ffi::ResultBuffer<ffi::DataType::F64> F
) {


  if (dim0(t) != N) return shape_error("matmul_upper shape mismatch");

  if (dim0(c) != J) return shape_error("matmul_upper shape mismatch");

  if (dim0(U) != N || dim1(U) != J) return shape_error("matmul_upper shape mismatch");

  if (dim0(V) != N || dim1(V) != J) return shape_error("matmul_upper shape mismatch");

  if (dim0(Y) != N || dim1(Y) != nrhs) return shape_error("matmul_upper shape mismatch");


#define FIXED_SIZE_MAP(SIZE)                                                        \
  {                                                                                 \
    Eigen::Map<const Eigen::VectorXd> t_(t.typed_data(), N, 1); \
    Eigen::Map<const Eigen::VectorXd> c_(c.typed_data(), J, 1); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> U_(U.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> V_(V.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Y_(Y.typed_data(), N, dim1(Y)); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Z_(Z->typed_data(), N, dim1(Z)); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> F_(F->typed_data(), N, flat_cols(F)); \
    Z_.setZero(); \
    F_.setZero(); \
    celerite2::core::matmul_upper( t_, c_, U_, V_, Y_, Z_,F_); \
  }
  UNWRAP_CASES_FEW
#undef FIXED_SIZE_MAP

  return ffi::Error::Success();
}

XLA_FFI_DEFINE_HANDLER_SYMBOL(
    matmul_upper, Matmul_upperImpl,
    ffi::Ffi::Bind()
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // t
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // c
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // U
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // V
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // Y
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // Z
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // F
);


ffi::Error matmul_upper_revImpl(
    ffi::Buffer<ffi::DataType::F64> t,
    ffi::Buffer<ffi::DataType::F64> c,
    ffi::Buffer<ffi::DataType::F64> U,
    ffi::Buffer<ffi::DataType::F64> V,
    ffi::Buffer<ffi::DataType::F64> Y,
    ffi::Buffer<ffi::DataType::F64> Z,
    ffi::Buffer<ffi::DataType::F64> F,
    ffi::Buffer<ffi::DataType::F64> bZ,
    ffi::ResultBuffer<ffi::DataType::F64> bt,
    ffi::ResultBuffer<ffi::DataType::F64> bc,
    ffi::ResultBuffer<ffi::DataType::F64> bU,
    ffi::ResultBuffer<ffi::DataType::F64> bV,
    ffi::ResultBuffer<ffi::DataType::F64> bY
) {


  if (dim0(t) != N) return shape_error("matmul_upper_rev shape mismatch");

  if (dim0(c) != J) return shape_error("matmul_upper_rev shape mismatch");

  if (dim0(U) != N || dim1(U) != J) return shape_error("matmul_upper_rev shape mismatch");

  if (dim0(V) != N || dim1(V) != J) return shape_error("matmul_upper_rev shape mismatch");

  if (dim0(Y) != N || dim1(Y) != nrhs) return shape_error("matmul_upper_rev shape mismatch");

  if (dim0(Z) != N || dim1(Z) != nrhs) return shape_error("matmul_upper_rev shape mismatch");


  if (dim0(bZ) != N || dim1(bZ) != nrhs) return shape_error("matmul_upper_rev shape mismatch");


#define FIXED_SIZE_MAP(SIZE)                                                        \
  {                                                                                 \
    Eigen::Map<const Eigen::VectorXd> t_(t.typed_data(), N, 1); \
    Eigen::Map<const Eigen::VectorXd> c_(c.typed_data(), J, 1); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> U_(U.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> V_(V.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Y_(Y.typed_data(), N, dim1(Y)); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Z_(Z.typed_data(), N, dim1(Z)); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> F_(F.typed_data(), N, dim1(F)); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> bZ_(bZ.typed_data(), N, dim1(bZ)); \
    Eigen::Map<Eigen::VectorXd> bt_(bt->typed_data(), N, 1); \
    Eigen::Map<Eigen::VectorXd> bc_(bc->typed_data(), J, 1); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> bU_(bU->typed_data(), N, J); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> bV_(bV->typed_data(), N, J); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> bY_(bY->typed_data(), N, dim1(bY)); \
    bt_.setZero(); \
    bc_.setZero(); \
    bU_.setZero(); \
    bV_.setZero(); \
    bY_.setZero(); \
    celerite2::core::matmul_upper_rev( t_, c_, U_, V_, Y_, Z_, F_, bZ_, bt_,bc_,bU_,bV_,bY_); \
  }
  UNWRAP_CASES_FEW
#undef FIXED_SIZE_MAP

  return ffi::Error::Success();
}

XLA_FFI_DEFINE_HANDLER_SYMBOL(
    matmul_upper_rev, matmul_upper_revImpl,
    ffi::Ffi::Bind()
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // t
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // c
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // U
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // V
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // Y
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // Z
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // F
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // bZ
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bt
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bc
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bU
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bV
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // bY
);



ffi::Error General_matmul_lowerImpl(
    ffi::Buffer<ffi::DataType::F64> t1,
    ffi::Buffer<ffi::DataType::F64> t2,
    ffi::Buffer<ffi::DataType::F64> c,
    ffi::Buffer<ffi::DataType::F64> U,
    ffi::Buffer<ffi::DataType::F64> V,
    ffi::Buffer<ffi::DataType::F64> Y,
    ffi::ResultBuffer<ffi::DataType::F64> Z,
    ffi::ResultBuffer<ffi::DataType::F64> F
) {


  if (dim0(t1) != N) return shape_error("general_matmul_lower shape mismatch");

  if (dim0(t2) != M) return shape_error("general_matmul_lower shape mismatch");

  if (dim0(c) != J) return shape_error("general_matmul_lower shape mismatch");

  if (dim0(U) != N || dim1(U) != J) return shape_error("general_matmul_lower shape mismatch");

  if (dim0(V) != M || dim1(V) != J) return shape_error("general_matmul_lower shape mismatch");

  if (dim0(Y) != M || dim1(Y) != nrhs) return shape_error("general_matmul_lower shape mismatch");


#define FIXED_SIZE_MAP(SIZE)                                                        \
  {                                                                                 \
    Eigen::Map<const Eigen::VectorXd> t1_(t1.typed_data(), N, 1); \
    Eigen::Map<const Eigen::VectorXd> t2_(t2.typed_data(), M, 1); \
    Eigen::Map<const Eigen::VectorXd> c_(c.typed_data(), J, 1); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> U_(U.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> V_(V.typed_data(), M, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Y_(Y.typed_data(), M, dim1(Y)); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Z_(Z->typed_data(), N, dim1(Z)); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> F_(F->typed_data(), M, flat_cols(F)); \
    Z_.setZero(); \
    F_.setZero(); \
    celerite2::core::general_matmul_lower( t1_, t2_, c_, U_, V_, Y_, Z_,F_); \
  }
  UNWRAP_CASES_MOST
#undef FIXED_SIZE_MAP

  return ffi::Error::Success();
}

XLA_FFI_DEFINE_HANDLER_SYMBOL(
    general_matmul_lower, General_matmul_lowerImpl,
    ffi::Ffi::Bind()
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // t1
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // t2
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // c
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // U
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // V
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // Y
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // Z
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // F
);



ffi::Error General_matmul_upperImpl(
    ffi::Buffer<ffi::DataType::F64> t1,
    ffi::Buffer<ffi::DataType::F64> t2,
    ffi::Buffer<ffi::DataType::F64> c,
    ffi::Buffer<ffi::DataType::F64> U,
    ffi::Buffer<ffi::DataType::F64> V,
    ffi::Buffer<ffi::DataType::F64> Y,
    ffi::ResultBuffer<ffi::DataType::F64> Z,
    ffi::ResultBuffer<ffi::DataType::F64> F
) {


  if (dim0(t1) != N) return shape_error("general_matmul_upper shape mismatch");

  if (dim0(t2) != M) return shape_error("general_matmul_upper shape mismatch");

  if (dim0(c) != J) return shape_error("general_matmul_upper shape mismatch");

  if (dim0(U) != N || dim1(U) != J) return shape_error("general_matmul_upper shape mismatch");

  if (dim0(V) != M || dim1(V) != J) return shape_error("general_matmul_upper shape mismatch");

  if (dim0(Y) != M || dim1(Y) != nrhs) return shape_error("general_matmul_upper shape mismatch");


#define FIXED_SIZE_MAP(SIZE)                                                        \
  {                                                                                 \
    Eigen::Map<const Eigen::VectorXd> t1_(t1.typed_data(), N, 1); \
    Eigen::Map<const Eigen::VectorXd> t2_(t2.typed_data(), M, 1); \
    Eigen::Map<const Eigen::VectorXd> c_(c.typed_data(), J, 1); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> U_(U.typed_data(), N, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, SIZE, order<SIZE>::value>> V_(V.typed_data(), M, J); \
    Eigen::Map<const Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Y_(Y.typed_data(), M, dim1(Y)); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> Z_(Z->typed_data(), N, dim1(Z)); \
    Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> F_(F->typed_data(), M, flat_cols(F)); \
    Z_.setZero(); \
    F_.setZero(); \
    celerite2::core::general_matmul_upper( t1_, t2_, c_, U_, V_, Y_, Z_,F_); \
  }
  UNWRAP_CASES_MOST
#undef FIXED_SIZE_MAP

  return ffi::Error::Success();
}

XLA_FFI_DEFINE_HANDLER_SYMBOL(
    general_matmul_upper, General_matmul_upperImpl,
    ffi::Ffi::Bind()
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // t1
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // t2
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // c
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // U
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // V
        .Arg<ffi::Buffer<ffi::DataType::F64>>()  // Y
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // Z
        .Ret<ffi::Buffer<ffi::DataType::F64>>()  // F
);



// Pybind --------------------------------------------------------------------
template <auto* Fn>
py::capsule Encapsulate() {
  return py::capsule(reinterpret_cast<void*>(Fn), "xla._CUSTOM_CALL_TARGET");
}

PYBIND11_MODULE(xla_ops, m) {

  m.def("factor", &Encapsulate<factor>);
  m.def("factor_rev", &Encapsulate<factor_rev>);

  m.def("solve_lower", &Encapsulate<solve_lower>);
  m.def("solve_lower_rev", &Encapsulate<solve_lower_rev>);

  m.def("solve_upper", &Encapsulate<solve_upper>);
  m.def("solve_upper_rev", &Encapsulate<solve_upper_rev>);

  m.def("matmul_lower", &Encapsulate<matmul_lower>);
  m.def("matmul_lower_rev", &Encapsulate<matmul_lower_rev>);

  m.def("matmul_upper", &Encapsulate<matmul_upper>);
  m.def("matmul_upper_rev", &Encapsulate<matmul_upper_rev>);

  m.def("general_matmul_lower", &Encapsulate<general_matmul_lower>);

  m.def("general_matmul_upper", &Encapsulate<general_matmul_upper>);

}
